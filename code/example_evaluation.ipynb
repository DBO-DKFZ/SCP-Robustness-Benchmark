{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplary Evaluation\n",
    "\n",
    "For evaluation, we always calculate the unadjusted and adjusted performance. Therefore it is necessary to provide an appropriate baseline. In our case, we use AlexNet as the baseline which we have made available for download (see README). \n",
    "\n",
    "After a user has sent off their diagnostic prediction scores using our provided template files, he/she will receive corresponding result files which contain the unadjusted metrics for SAM, SAM-C and SAM-P for each individual transformation. From this, the unadjusted/adjusted *mCBE*, *relative mCBE* and *mFR* can can be calculated using our provided code interactively or via the command line. \n",
    "\n",
    "**mCBE and mFR**\n",
    "\n",
    "Calculating unadjusted/adjusted *mCBE* and *mFR* requires the file path to a scored SAM-C/P or SAM-C-Eextra/P-Extra submission file and the corresponding baseline file (preferrably our AlexNet baseline). Users need to make sure, that the DatasetName (e.g. SAM-P or SAM-C) is always matched for both file paths. \n",
    "\n",
    "**relative mCBE**\n",
    "\n",
    "Calculating unadjusted/adjusted *relative mCBE* requires two additional file path parameters. Both file paths should point to a file which contains the 'clean' performance (i.e. performance of the user classifier and baseline classifier on SAM).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAM-C performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unadjusted mCBE: 26.99\n",
      "Adjusted mCBE: 88.29\n"
     ]
    }
   ],
   "source": [
    "perf = evaluate(f\"example_sub/ResNet50_SAM-C.csv\", \"baseline/Baseline_SAM-C.csv\")\n",
    "print(f\"Unadjusted mCBE: {perf['unadjusted']*100:.2f}\")\n",
    "print(f\"Adjusted mCBE: {perf['adjusted']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unadjusted relative mCBE: 8.82\n",
      "Adjusted relative mCBE: 118.40\n"
     ]
    }
   ],
   "source": [
    "perf = evaluate(f\"example_sub/ResNet50_SAM-C.csv\", \"baseline/Baseline_SAM-C.csv\", f\"example_sub/ResNet50_SAM.csv\", \"baseline/Baseline_SAM.csv\" )\n",
    "print(f\"Unadjusted relative mCBE: {perf['unadjusted']*100:.2f}\")\n",
    "print(f\"Adjusted relative mCBE: {perf['adjusted']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAM-P performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unadjusted mFR: 6.73\n",
      "Adjusted mFR: 138.71\n"
     ]
    }
   ],
   "source": [
    "perf = evaluate(f\"example_sub/ResNet50_SAM-P.csv\", \"baseline/Baseline_SAM-P.csv\")\n",
    "print(f\"Unadjusted mFR: {perf['unadjusted']*100:.2f}\")\n",
    "print(f\"Adjusted mFR: {perf['adjusted']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAM-C-Extra performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unadjusted mCBE: 28.16\n",
      "Adjusted mCBE: 87.40\n"
     ]
    }
   ],
   "source": [
    "perf = evaluate(f\"example_sub/ResNet50_SAM-C-Extra.csv\", \"baseline/Baseline_SAM-C-Extra.csv\")\n",
    "print(f\"Unadjusted mCBE: {perf['unadjusted']*100:.2f}\")\n",
    "print(f\"Adjusted mCBE: {perf['adjusted']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unadjusted relative mCBE: 9.98\n",
      "Adjusted relative mCBE: 94.32\n"
     ]
    }
   ],
   "source": [
    "perf = evaluate(f\"example_sub/ResNet50_SAM-C-Extra.csv\", \"baseline/Baseline_SAM-C-Extra.csv\", f\"example_sub/ResNet50_SAM.csv\", \"baseline/Baseline_SAM.csv\")\n",
    "print(f\"Unadjusted relative mCBE: {perf['unadjusted']*100:.2f}\")\n",
    "print(f\"Adjusted relative mCBE: {perf['adjusted']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAM-P-Extra performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unadjusted mFR: 6.64\n",
      "Adjusted mFR: 141.03\n"
     ]
    }
   ],
   "source": [
    "perf = evaluate(f\"example_sub/ResNet50_SAM-P-Extra.csv\", \"baseline/Baseline_SAM-P-Extra.csv\")\n",
    "print(f\"Unadjusted mFR: {perf['unadjusted']*100:.2f}\")\n",
    "print(f\"Adjusted mFR: {perf['adjusted']*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAM-C performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unadjusted metric: 26.99\n",
      "Adjusted metric: 88.29\n"
     ]
    }
   ],
   "source": [
    "! python evaluation.py -uf \"example_sub/ResNet50_SAM-C.csv\" -bf \"baseline/Baseline_SAM-C.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unadjusted metric: 8.82\n",
      "Adjusted metric: 118.40\n"
     ]
    }
   ],
   "source": [
    "! python evaluation.py -uf \"example_sub/ResNet50_SAM-C.csv\" -bf \"baseline/Baseline_SAM-C.csv\" -cluf \"example_sub/ResNet50_SAM.csv\" -clbf \"baseline/Baseline_SAM.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAM-P performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unadjusted metric: 6.73\n",
      "Adjusted metric: 138.71\n"
     ]
    }
   ],
   "source": [
    "! python evaluation.py -uf \"example_sub/ResNet50_SAM-P.csv\" -bf \"baseline/Baseline_SAM-P.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAM-C-Extra performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unadjusted metric: 28.16\n",
      "Adjusted metric: 87.40\n"
     ]
    }
   ],
   "source": [
    "! python evaluation.py -uf \"example_sub/ResNet50_SAM-C-Extra.csv\" -bf \"baseline/Baseline_SAM-C-Extra.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unadjusted metric: 9.98\n",
      "Adjusted metric: 94.32\n"
     ]
    }
   ],
   "source": [
    "! python evaluation.py -uf \"example_sub/ResNet50_SAM-C-Extra.csv\" -bf \"baseline/Baseline_SAM-C-Extra.csv\" -cluf \"example_sub/ResNet50_SAM.csv\" -clbf \"baseline/Baseline_SAM.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAM-P-Extra performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unadjusted metric: 6.64\n",
      "Adjusted metric: 141.03\n"
     ]
    }
   ],
   "source": [
    "! python evaluation.py -uf \"example_sub/ResNet50_SAM-P-Extra.csv\" -bf \"baseline/Baseline_SAM-P-Extra.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
